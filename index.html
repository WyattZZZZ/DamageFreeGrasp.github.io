<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">DamageFree Grasping: A multimodel ...</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Ziye Zhang</a><sup>*</sup><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">XiaXiao Yu</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Jinyun Hao</a><sup>1</sup></span><br>
                    <span class="author-block">
                      <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Yinghao Zhang</a><sup>1</sup>,</span>
                      <span class="author-block">
                        <a href="FIFTH AUTHOR PERSONAL LINK" target="_blank">Jingwei Li</a><sup>1</sup>,</span>
                        <span class="author-block">
                          <a href="SIXTH AUTHOR PERSONAL LINK" target="_blank">Xiaoyang Li</a><sup>2</sup>,</span>
                          <span class="author-block">
                            <a href="SEVENTH AUTHOR PERSONAL LINK" target="_blank">Yongqiang Wang</a><sup>2</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Xi'an Jiaotong-Liverpool Univeristy<sup>1</sup><br>Liverpool University<sup>2</sup><br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Model Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/moojink?search_models=oft" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="static/images/hf_icon.svg" />
                  </span>
                  <span>Models</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin ullamcorper tellus sed ante aliquam tempus. Etiam porttitor urna feugiat nibh elementum, et tempor dolor mattis. Donec accumsan enim augue, a vulputate nisi sodales sit amet. Proin bibendum ex eget mauris cursus euismod nec et nibh. Maecenas ac gravida ante, nec cursus dui. Vivamus purus nibh, placerat ac purus eget, sagittis vestibulum metus. Sed vestibulum bibendum lectus gravida commodo. Pellentesque auctor leo vitae sagittis suscipit.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <!-- Your video here -->
          <source src="static/videos/banner_video.mp4"
          type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <!-- Your video here -->
          <source src="static/videos/banner_video.mp4"
          type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <!-- Your video here -->
          <source src="static/videos/banner_video.mp4"
          type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!-- Paper Model -->
<section class="hero is-small is-light">
  
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Model Structure</h2>
        <div class="content has-text-justified">
          <div class="content has-text-justified has-text-centered">
            <img src="static/images/carousel1.jpg" />
          <p>
            In the land of Whimsy, Tung Tung Tung Sahur met Tralalero Tralala, who was chasing Bombardiro Crocodilo. Suddenly, Bombombini Guzini appeared, carrying Boneca Ambalam on his back. La Vacca Saturnosaturnita watched from afar, while Brr Brr Patapim tried to catch a glimpse of Giraffa Meloniera. Glorbo Frutto Drillo joined them, bringing along Il Cacto Hipopotoma. Chimpazini Bananini swung in, holding a giant banana.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper model -->


<!-- Paper results -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
          <h2 class="title is-3">Experiments</h2>

          <h3 class="title is-4">Direct Evaluations on Multiple Robot Platforms</h3>
          <img src="static/images/bridge_results.jpg" />
          <div class="content has-text-justified">

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
              <tr>
                <p>
                  We evaluate OpenVLA's ability to control multiple robot platforms ``out-of-the-box'' across two setups: the WidowX setup 
                  from Bridge V2 and the Google Robot from the RT-series of papers. Our results show that OpenVLA sets a new state of the art, 
                  outperforming prior generalist policies RT-1-X and Octo. Notably, as a product of the added data diversity and new model
                  components, it also outperforms RT-2-X, a 55B parameter closed VLA.
                </p>
              </tr>
              <tr>
                <td width="50%">
                  <p>
                    We test OpenVLA across a wide range of generalization tasks, such as 
                    <strong>visual</strong> (unseen backgrounds, distractor objects, colors/appearances of objects); 
                    <strong>motion</strong> (unseen object positions/orientations); 
                    <strong>physical</strong> (unseen object sizes/shapes); 
                    and <strong>semantic</strong> (unseen target objects, instructions, and concepts from the Internet) generalization. 
                    Qualitatively, we find that both RT-2-X and OpenVLA exhibit markedly more robust behaviors than the other tested model, 
                    such as approaching the correct object when distractor objects are present, properly orienting the robot's end-effector
                    to align with the orientation of the target object, and even recovering from mistakes such as insecurely grasping objects
                  </p>
                </td>
                <td width="50%">
                  <img src="static/images/rt1_results.jpg">
                </td>
              </tr>
            </table>
          </div>

          <br>
          <h3 class="title is-4">Data-Efficient Adaptation to New Robot Setups</h3>
          
          <div class="content has-text-justified">
            <img src="static/images/finetune_results.jpg" />
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
              <tr>
                <p>
                  Effective fine-tuning of VLA models to new tasks and robot setups is largely unexplored, 
                  yet is key for their widespread adoption. We investigate OpenVLA’s ability to be quickly adapted to a new robot setup
                  in two domains: Franka-Tabletop, a stationary, table-mounted Franka Emika Panda 7-DoF robot arm, controlled 
                  at a frequency of 5 Hz; and Franka-DROID, the Franka robot arm setup from the recently released <a href="https://droid-dataset.github.io/">DROID dataset</a>, controlled at 15 Hz. 

                </p>
              </tr>
              <tr>
                <p>
                  We compare to Diffusion Policy, a state of the art data-efficient imitation learning approach, trained from scratch.
                  Additionally, we evaluate Octo fine-tuned on the target dataset. OpenVLA clearly outperforms Octo across most tasks.
                  Diffusion policy is strongest on narrower, more precise tasks, while OpenVLA shows better performance on tasks that 
                  require grounding language to behavior in multi-task, multi-object settings.
                  OpenVLA is the only approach that achieves at least 50% success rate across all tested
                  tasks, suggesting that it can be a strong default option for imitation learning tasks, particularly if they
                  involve a diverse set of language instructions.
                </p>
              </tr>
            </table>
            
          </div>
          
          <br>
          <h3 class="title is-4">Parameter-Efficient Fine-Tuning</h3>
          <div class="content has-text-justified">
            <img src="static/images/lora_table.png">
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
              <tr>
                <p>
                  We test various approaches for parameter-efficient fine-tuning of OpenVLA policies across multiple Franka-Tabletop tasks.
                  We find that only fine-tuning the network’s last layer or freezing the vision encoder leads to poor performance.
                  LoRA achieves the best trade-off between performance and training memory consumption, matching
                  full fine-tuning performance while fine-tuning only 1.4% of the parameters. 
                </p>
              </tr>
            </table>
          </div>


        <br>
        </section>
<!-- End paper experiment -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
